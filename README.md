# Data_Processing_Using_Spark

This Coursera project is from the course: Introduction to Big Data with Spark and Hadoop, which is a part of the 13 course series: IBM Data Engineering Professional Certificate.

The goal of this project is to practice ETL using PySpark with two datasets.

Please see the FinalAssignment.ipynb file for specifics of each part of the project.

### Scenario
You have been hired as a Junior Data Engineer by BDPS Corporation and you have been provided with links to two raw datasets that you need to acquire and perform ETL on using PySpark and Hive warehouse.

### Project Overview
This practice project focuses on data transformation and integration using PySpark. You will work with two datasets, and perform various transformations such as adding columns, renaming columns, dropping unnecessary columns, joining dataframes, and finally, writing the results into a Hive warehouse and an HDFS file system.
